{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Agentic RAG Pipeline\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/agentic-rag-workshop/blob/main/agentic-rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/agentic-rag-workshop.git\n",
    "    %cd union-rag\n",
    "    %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Setup\n",
    "\n",
    "Install python libraries by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the libraries are being installed:\n",
    "- Sign up for a free Union account: https://signup.union.ai/\n",
    "- Go to the Union dashboard: https://serverless.union.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Union in this notebook session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create login --auth device-flow --serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Simple Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple_wf.py\n",
    "from flytekit import task, workflow\n",
    "\n",
    "@task\n",
    "def hello_world(name: str) -> str:\n",
    "    return f\"Hello, {name}\"\n",
    "\n",
    "@workflow\n",
    "def main(name: str) -> str:\n",
    "    return hello_world(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run locally\n",
    "!union run simple_wf.py main --name \"Workshop Attendee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on Union\n",
    "!union run --remote simple_wf.py main --name \"Workshop Attendee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the main workflow inputs\n",
    "!union run simple_wf.py main --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create OpenAI API Key Secret on Union\n",
    "\n",
    "First go to https://platform.openai.com/account/api-keys and create an OpenAI API key.\n",
    "\n",
    "Then, run the following command to make the secret accessible on Union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create secret openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union get secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have issues with the secret, you can delete it by uncommenting the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!union delete secret openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RAG Workflow\n",
    "\n",
    "> To run, we must first learn how to walk.\n",
    "\n",
    "In the first part of this workshop, we'll build a simple RAG workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./static/rag-workflow.png\" alt=\"Simple RAG Workflow\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Image Spec\n",
    "\n",
    "An `ImageSpec` is Union's way of specifying a container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile custom_image.py\n",
    "from flytekit import ImageSpec\n",
    "\n",
    "image = ImageSpec(\n",
    "    packages=[\n",
    "        \"beautifulsoup4==4.12.3\",\n",
    "        \"chromadb==0.5.3\",\n",
    "        \"langchain==0.3.2\",\n",
    "        \"langchain-community==0.3.1\",\n",
    "        \"langchain-openai==0.2.2\",\n",
    "        \"langchain-text-splitters==0.3.0\",\n",
    "        \"tiktoken==0.7.0\",\n",
    "        \"xmltodict==0.13.0\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Vector Store\n",
    "\n",
    "The first step to doing this is to create a vector store of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vector_store.py\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "from flytekit import task, Deck, Secret\n",
    "from flytekit.deck import MarkdownRenderer\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from union.artifacts import Artifact, DataCard\n",
    "\n",
    "from custom_image import image\n",
    "from utils import get_pubmed_loader, parse_doc, generate_data_card, set_openai_api_key\n",
    "\n",
    "\n",
    "# Define the vector store artifact\n",
    "VectorStore = Artifact(name=\"vector-store\")\n",
    "\n",
    "\n",
    "@task(\n",
    "    container_image=image,\n",
    "    cache=True,\n",
    "    cache_version=\"13\",\n",
    "    secret_requests=[Secret(key=\"openai_api_key\")],\n",
    "    enable_deck=True,\n",
    "    deck_fields=[],\n",
    ")\n",
    "def create_vector_store(\n",
    "    query: str,\n",
    "    load_max_docs: Optional[int] = None,\n",
    "    chunk_size: int = 100,\n",
    "    chunk_overlap: int = 50,\n",
    ") -> Annotated[FlyteDirectory, VectorStore]:\n",
    "    \"\"\"Create a vector store of pubmed documents based on a query.\"\"\"\n",
    "\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    load_max_docs = load_max_docs or 10\n",
    "\n",
    "    # load the documents\n",
    "    loader = get_pubmed_loader(\n",
    "        query,\n",
    "        load_max_docs=load_max_docs,\n",
    "        max_retry=200,\n",
    "        sleep_time=1.0,\n",
    "    )\n",
    "    docs = [parse_doc(doc) for doc in loader.load()]\n",
    "\n",
    "    # split the documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # create a Chroma vector store\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=doc_splits,\n",
    "        collection_name=\"rag-chroma\",\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "    # create a data card\n",
    "    data_card = generate_data_card(docs)\n",
    "    Deck(\"Data Card\", MarkdownRenderer().to_html(data_card))\n",
    "\n",
    "    return VectorStore.create_from(\n",
    "        FlyteDirectory(path=vector_store._persist_directory),\n",
    "        DataCard(data_card),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store\n",
    "!union run --remote vector_store.py create_vector_store --query \"CRISPR therapy\" --load_max_docs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RAG Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple_rag.py\n",
    "from typing import Optional\n",
    "\n",
    "from flytekit import workflow, Deck, Resources, Secret\n",
    "from flytekit.deck import MarkdownRenderer\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from union.actor import ActorEnvironment\n",
    "from union.artifacts import Artifact\n",
    "\n",
    "from custom_image import image\n",
    "from utils import set_openai_api_key\n",
    "\n",
    "\n",
    "DEFAULT_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks in the biomedical domain.\n",
    "Use only the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. Make the answer as\n",
    "detailed as possible. If the answer contains acronyms, make sure to expand on them.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "actor = ActorEnvironment(\n",
    "    name=\"simple-rag\",\n",
    "    ttl_seconds=180,\n",
    "    container_image=image,\n",
    "    requests=Resources(cpu=\"2\", mem=\"8Gi\"),\n",
    "    secret_requests=[Secret(key=\"openai_api_key\")],\n",
    ")\n",
    "\n",
    "VectorStore = Artifact(name=\"vector-store\")\n",
    "\n",
    "\n",
    "@actor.task(enable_deck=True, deck_fields=[])\n",
    "def retrieve(\n",
    "    question: str,\n",
    "    vector_store: FlyteDirectory,\n",
    ") -> str:\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    vector_store.download()\n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"rag-chroma\",\n",
    "        persist_directory=vector_store.path,\n",
    "        embedding_function=OpenAIEmbeddings(),\n",
    "    )\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 8},\n",
    "    )\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retriever.invoke(question))\n",
    "    Deck(\"Context\", MarkdownRenderer().to_html(context))\n",
    "    return context\n",
    "\n",
    "\n",
    "@actor.task(enable_deck=True, deck_fields=[])\n",
    "def generate(\n",
    "    question: str,\n",
    "    context: str,\n",
    "    prompt_template: Optional[str] = None,\n",
    ") -> str:\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    prompt = PromptTemplate.from_template(prompt_template or DEFAULT_PROMPT_TEMPLATE)\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.9)\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"question\": question, \"context\": context})\n",
    "    Deck(\"Answer\", MarkdownRenderer().to_html(answer))\n",
    "    return answer\n",
    "\n",
    "\n",
    "@workflow\n",
    "def run(\n",
    "    question: str,\n",
    "    vector_store: FlyteDirectory = VectorStore.query(),\n",
    "    prompt_template: Optional[str] = None,\n",
    ") -> str:\n",
    "    context = retrieve(question, vector_store)\n",
    "    return generate(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        prompt_template=prompt_template,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simple RAG workflow\n",
    "!union run --remote simple_rag.py run --question \"What are the latest CRISPR therapies?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making RAG Agentic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./static/agentic-rag-workflow.png\" alt=\"Agentic RAG Workflow\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agentic_types.py\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class RetrieverAction(Enum):\n",
    "    tools = \"tools\"\n",
    "    end = \"end\"\n",
    "\n",
    "\n",
    "class GraderAction(Enum):\n",
    "    generate = \"generate\"\n",
    "    rewrite = \"rewrite\"\n",
    "    end = \"end\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    \"\"\"Json-encoded message.\"\"\"\n",
    "\n",
    "    data: str\n",
    "\n",
    "    def to_langchain(self):\n",
    "        from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "\n",
    "        data = json.loads(self.data)\n",
    "        message_type = data.get(\"type\", data.get(\"role\"))\n",
    "        return {\"ai\": AIMessage, \"tool\": ToolMessage, \"human\": HumanMessage}[message_type](**data)\n",
    "\n",
    "    @classmethod\n",
    "    def from_langchain(cls, message):\n",
    "        return cls(data=json.dumps(message.dict()))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"A list of messages capturing the state of the RAG execution graph.\"\"\"\n",
    "\n",
    "    messages: list[Message]\n",
    "\n",
    "    def to_langchain(self) -> dict:\n",
    "        return {\"messages\": [message.to_langchain() for message in self.messages]}\n",
    "\n",
    "    def append(self, message):\n",
    "        self.messages.append(Message.from_langchain(message))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        message: Message = self.messages[index]\n",
    "        return message.to_langchain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agentic_nodes.py\n",
    "from flytekit import Deck, Secret\n",
    "from flytekit.deck import MarkdownRenderer\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from union.actor import ActorEnvironment\n",
    "\n",
    "from agentic_types import RetrieverAction, GraderAction, Message, AgentState\n",
    "from custom_image import image\n",
    "from utils import get_vector_store_retriever, set_openai_api_key\n",
    "\n",
    "\n",
    "actor = ActorEnvironment(\n",
    "    name=\"agentic-rag\",\n",
    "    ttl_seconds=180,\n",
    "    container_image=image,\n",
    "    secret_requests=[Secret(key=\"openai_api_key\")],\n",
    ")\n",
    "\n",
    "\n",
    "@actor.task(cache=True, cache_version=\"0\")\n",
    "def init_state(user_message: str) -> AgentState:\n",
    "    \"\"\"Initialize the AgentState with the user's message.\"\"\"\n",
    "    from langchain_core.messages import HumanMessage\n",
    "\n",
    "    return AgentState(messages=[Message.from_langchain(HumanMessage(user_message))])\n",
    "\n",
    "\n",
    "@actor.task\n",
    "def retriever_agent(\n",
    "    state: AgentState,\n",
    "    vector_store: FlyteDirectory,\n",
    ") -> tuple[AgentState, RetrieverAction]:\n",
    "    \"\"\"Invokes the agent to either end the loop or call the retrieval tool.\"\"\"\n",
    "\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    \n",
    "    set_openai_api_key()\n",
    "\n",
    "    vector_store.download()\n",
    "    retriever_tool = get_vector_store_retriever(vector_store.path)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an biomedical research assistant that can retrieve\n",
    "        documents and answer questions based on those documents.\n",
    "\n",
    "        Here is the user question: {question} \\n\n",
    "\n",
    "        If the question is related to biomedical research, call the relevant\n",
    "        tool that you have access to. If the question is not related to\n",
    "        biomedical research, end the loop with a response that the question\n",
    "        is not relevant.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    question_message = state[-1]\n",
    "    assert question_message.type == \"human\"\n",
    "\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4-turbo\").bind_tools([retriever_tool])\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"question\": question_message.content})\n",
    "\n",
    "    # Get agent's decision to call the retrieval tool or end the loop\n",
    "    action = RetrieverAction.end\n",
    "    if hasattr(response, \"tool_calls\") and len(response.tool_calls) > 0:\n",
    "        action = RetrieverAction.tools\n",
    "\n",
    "    state.append(response)\n",
    "    return state, action\n",
    "\n",
    "\n",
    "@actor.task\n",
    "def retrieve(\n",
    "    state: AgentState,\n",
    "    vector_store: FlyteDirectory,\n",
    ") -> AgentState:\n",
    "    \"\"\"Retrieves documents from the vector store.\"\"\"\n",
    "\n",
    "    from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    vector_store.download()\n",
    "    retriever_tool = get_vector_store_retriever(vector_store.path)\n",
    "\n",
    "    agent_message = state[-1]\n",
    "    assert isinstance(agent_message, AIMessage)\n",
    "    assert len(agent_message.tool_calls) == 1\n",
    "\n",
    "    # invoke the tool to retrieve documents from the vector store\n",
    "    tool_call = agent_message.tool_calls[0]\n",
    "    content = retriever_tool.invoke(tool_call[\"args\"])\n",
    "    response = ToolMessage(content=content, tool_call_id=tool_call[\"id\"])\n",
    "    state.append(response)\n",
    "    return state\n",
    "\n",
    "\n",
    "@actor.task\n",
    "def grader_agent(state: AgentState) -> GraderAction:\n",
    "    \"\"\"Determines whether the retrieved documents are relevant to the question.\"\"\"\n",
    "\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    # Restrict the LLM's output to be a binary \"yes\" or \"no\"\n",
    "    class Grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "    llm = model.with_structured_output(Grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved \n",
    "        document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the\n",
    "        user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the\n",
    "        document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm\n",
    "\n",
    "    messages = state.to_langchain()[\"messages\"]\n",
    "\n",
    "    # get the last \"human\" and \"tool\" message, which contains the question and\n",
    "    # retrieval tool context, respectively\n",
    "    questions = [m for m in messages if m.type == \"human\"]\n",
    "    contexts = [m for m in messages if m.type == \"tool\"]\n",
    "    question = questions[-1]\n",
    "    context = contexts[-1]\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question.content, \"context\": context.content})\n",
    "    score = scored_result.binary_score\n",
    "    return {\n",
    "        \"yes\": GraderAction.generate,\n",
    "        \"no\": GraderAction.rewrite,\n",
    "    }[score]\n",
    "\n",
    "\n",
    "@actor.task\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    \"\"\"Transform the query to produce a better question.\"\"\"\n",
    "\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    messages = state.to_langchain()[\"messages\"]\n",
    "\n",
    "    # get the last \"human\", which contains the user question\n",
    "    questions = [m for m in messages if m.type == \"human\"]\n",
    "    question = questions[-1].content\n",
    "\n",
    "    class rewritten_question(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        question: str = Field(description=\"Rewritten question\")\n",
    "        reason: str = Field(description=\"Reasoning for the rewrite\")\n",
    "\n",
    "    rewrite_prompt = f\"\"\"\n",
    "    Look at the input and try to reason about the underlying semantic\n",
    "    intent / meaning. \\n\n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question and provide your reasoning.\n",
    "    \"\"\"\n",
    "\n",
    "    # define model with structured output for the question rewrite\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "    rewriter_model = model.with_structured_output(rewritten_question)\n",
    "\n",
    "    response = rewriter_model.invoke([HumanMessage(content=rewrite_prompt)])\n",
    "    message = HumanMessage(\n",
    "        content=response.question,\n",
    "        response_metadata={\"rewrite_reason\": response.reason},\n",
    "    )\n",
    "    state.append(message)\n",
    "    return state\n",
    "\n",
    "\n",
    "@actor.task\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate an answer based on the state.\"\"\"\n",
    "\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.messages import AIMessage\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    set_openai_api_key()\n",
    "\n",
    "    messages = state.to_langchain()[\"messages\"]\n",
    "\n",
    "    # get the last \"human\" and \"tool\" message, which contains the question and\n",
    "    # retrieval tool context, respectively\n",
    "    questions = [m for m in messages if m.type == \"human\"]\n",
    "    contexts = [m for m in messages if m.type == \"tool\"]\n",
    "    question = questions[-1]\n",
    "    context = contexts[-1]\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are an assistant for question-answering tasks in the biomedical domain.\n",
    "    Use the following pieces of retrieved context to answer the question. If you\n",
    "    don't know the answer, just say that you don't know. Make the answer as\n",
    "    detailed as possible. If the answer contains acronyms, make sure to expand\n",
    "    them.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"human\", system_message)])\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = rag_chain.invoke({\"context\": context.content, \"question\": question.content})\n",
    "    if isinstance(response, str):\n",
    "        response = AIMessage(response)\n",
    "\n",
    "    state.append(response)\n",
    "    return state\n",
    "\n",
    "\n",
    "@actor.task(enable_deck=True, deck_fields=[])\n",
    "def return_answer(state: AgentState) -> str:\n",
    "    \"\"\"Finalize the answer to return a string to the user.\"\"\"\n",
    "\n",
    "    if len(state.messages) == 1:\n",
    "        answer = f\"I'm sorry, I don't understand: '{state.messages}'\"\n",
    "    else:\n",
    "        data = state.messages[-1].to_langchain()\n",
    "        answer = data.content\n",
    "    Deck(\"Answer\", MarkdownRenderer().to_html(answer))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agentic_rag.py\n",
    "from flytekit import dynamic, workflow, Secret\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from union.actor import ActorEnvironment\n",
    "from union.artifacts import Artifact\n",
    "\n",
    "from agentic_types import RetrieverAction, GraderAction, AgentState\n",
    "from agentic_nodes import init_state, retriever_agent, retrieve, grader_agent, rewrite, generate, return_answer\n",
    "from custom_image import image\n",
    "\n",
    "\n",
    "actor = ActorEnvironment(\n",
    "    name=\"agentic-rag\",\n",
    "    ttl_seconds=900,\n",
    "    container_image=image,\n",
    "    secret_requests=[Secret(key=\"openai_api_key\")],\n",
    ")\n",
    "\n",
    "VectorStore = Artifact(name=\"vector-store\")\n",
    "\n",
    "# maximum number of question rewrites\n",
    "MAX_REWRITES = 10\n",
    "\n",
    "\n",
    "@dynamic\n",
    "def retrieval_router(\n",
    "    state: AgentState,\n",
    "    action: RetrieverAction,\n",
    "    vector_store: FlyteDirectory,\n",
    "    n_rewrites: int,\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    The first conditional branch in the RAG workflow. This determines whether\n",
    "    the agent loop should end or call the retrieval tool for grading.\n",
    "    \"\"\"\n",
    "\n",
    "    if action == RetrieverAction.end:\n",
    "        return state\n",
    "    elif action == RetrieverAction.tools:\n",
    "        state = retrieve(state=state, vector_store=vector_store)\n",
    "        grader_action = grader_agent(state=state)\n",
    "        return rewrite_or_generate_router(state, grader_action, vector_store, n_rewrites)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Invalid action '{action}'\")\n",
    "\n",
    "\n",
    "@dynamic\n",
    "def rewrite_or_generate_router(\n",
    "    state: AgentState,\n",
    "    grader_action: GraderAction,\n",
    "    vector_store: FlyteDirectory,\n",
    "    n_rewrites: int,\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    The second conditional branch in the RAG workflow. This determines whether\n",
    "    the rewrite the original user's query or generate the final answer.\n",
    "    \"\"\"\n",
    "    if grader_action == GraderAction.generate or n_rewrites >= MAX_REWRITES:\n",
    "        return generate(state=state)\n",
    "    elif grader_action == GraderAction.rewrite:\n",
    "        state = rewrite(state=state)\n",
    "        state, action = retriever_agent(state=state, vector_store=vector_store)\n",
    "        n_rewrites += 1\n",
    "        return retrieval_router(\n",
    "            state=state,\n",
    "            action=action,\n",
    "            vector_store=vector_store,\n",
    "            n_rewrites=n_rewrites,\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError(f\"Invalid action '{grader_action}'\")\n",
    "\n",
    "\n",
    "\n",
    "@workflow\n",
    "def run(\n",
    "    question: str,\n",
    "    vector_store: FlyteDirectory = VectorStore.query(),\n",
    ") -> str:\n",
    "    \"\"\"An agentic retrieval augmented generation workflow.\"\"\"\n",
    "    state = init_state(user_message=question)\n",
    "    state, action = retriever_agent(state=state, vector_store=vector_store)\n",
    "    state = retrieval_router(state, action, vector_store, n_rewrites=0)\n",
    "    return return_answer(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simple RAG workflow\n",
    "!union run --remote agentic_rag.py run --question \"What are the latest CRISPR therapies?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
